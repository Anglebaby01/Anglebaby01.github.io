### 爬虫基础
#### 0.爬虫的基本组成
+ URL管理模块
+ HTML下载模块
+ HTML解析模块
+ 数据存储模块
+ 爬虫调度模块
+ ##### 0.1 其他信息的了解
    + 概念：爬虫是一种按照一定的规则，自动抓取万维网信息的程序或脚本
    + robots:是否允许其他爬⾍(通⽤爬⾍即浏览器)爬取某些内容  爬虫不遵守robots
    + 爬虫不是黑客，它只能爬去到用户所能访问的数据 
#### 1.HTTP原理
+ ##### 1.1 URL和URI
    + URI（Unifor Resource Identifier）：统一资源标识符
    + URL（Universa Resource Locator）：统一资源定位符
    + URN（Universal Resource Name）：统一资源名称
    + URI = URL + URN
    + 通常情况下，网页链接使用的是URL
+ ##### 1.2 超文本（hypertext）
    + 网页源代码即是一系列HTML代码，网页源代码由超文本解析后，形成我们所看到的网页
+ ##### 1.3 HTTP和HTTPS
    + URL的开头会有http或https ，这就是访问资源需要的协议类型（有其他协议类型，但普遍是这两种）
    + HTTP（Hyper Text Transfer Protocol）：超文本传输协议。用于从网络传输超文本数据到本地浏览器的传送协议，它能保证高效而准确地传送超文本文档。
    + HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer）：HTTP + SSL（安全套接层，作用：加密超文本数），即HTTP的安全版。效率弱于HTTTP。
    + 凡是使用了 HTTPS 的网站，，都可以通过点击浏览器地址栏的锁头标志来查看网站认证之后的真实信息，也可以通过 CA 机构颁发的安全签章来查询。
        + 注意：
        + 1、某些网站虽然使用了 HTTPS 协议，但还是会被浏览器提示不安全，时浏览器就会提示“您的连接不是私密连接”，只是因为没有CA证书的认可，但认识SSL加密了的。
        + 2、爬取这样的站点，就需要设置忽略证书的选项，否则会提示 SSL 链接错误。
+ ##### 1.4 HTTP的请求过程 
    + 在浏览器中输入一个URL ，回车之后便会在浏览器中观察到页面内容 实际上，这个过程是
浏览器向网站所在的服务器发送了一个请求，网站服务器接收到这个请求后进行处理和解析，然后返
回对应的响应，接着传回给浏览器 响应里包含了页面的源代码等内容，浏览器再对其进行解析，便
将网页呈现了出来。
    + 如果输入的是域名则还需通过DNS解析返回IP地址后再发送请求。
    + 请求图解析
    [![HTTPnetwork.md.png](https://wx1.sbimg.cn/2020/04/29/HTTPnetwork.md.png)](https://sbimg.cn/image/XrVJU)
        + Name ：请求的名称，一般会将 RL 最后一部分内容当作名称
        + Status ：响应的状态码，这里显示为200代表响应是正常的通过状态码，我们可以判断发送了请求之后是得到了正常的响应
        + Type:请求的文梢类型 这里为document ，代表我们这次请求的是HTML文档，内容就是一些HTML代码
        + Initiator:请求源,用来标记请求是由哪个对象或进程发起的
        + Size:从服务器下载的文件和请求的资源大小 如果是从缓存中取得的资源，则该列会显示台om cache
        + Time:发起请求到获取响应所用的总时间
        + Waterfall：网络请求的可视化瀑布流
    + 点击name下条目可以看见具体的详细信息
    [![2.md.png](https://wx2.sbimg.cn/2020/04/29/2.md.png)](https://sbimg.cn/image/XO4RY)
        + 一般会有四个部分（有时是三个，看具体情况）：General、Response Headers（相应头）、Request Headers（请求头）、query string params(查询的参数，不一定有)
        + General：
            + Request URL：请求的 URL
            + Request Method：请求的方法
            + Status Code：响应状态码
            + Remote Address ：远程服务器的地址和端口
            + Referrer Policy ：Referrer 判别策略
        + query string params ：查询数据用的参数
        + 响应头和请求头是重点，具体的内容在下面
+ ##### 1.5 请求
    + 数据请求的过程（浏览器）：
    浏览器搜索域名->域名服务器DNS解析成IP地址返回到浏览器->浏览器通过IP地址链接到服务器，然后服务器在数据库中搜索并返回相应数据给浏览器
    + 请求，由客户端向服务端发出，可以分为4部分：
    请求方法（ Request Method ）\请求的网址( Request URL ）、请求头（ Request Headers )、请求体（ Request Body )
    + 1.请求方法：
        + GET和POST(这两种常用)
            + GET:请求页面，并返回页面内容 
            + POST:大多用于提交表单或上传文件，数据包含在请求体中
        + GET和POST的区别：
            + GET 请求中的参数包含在 URL 里面，数据可以在 URL 中看到，而POST 请求的 URL 会包含这些数据，数据都是通过表单形式传输的，会包含在请求体中
            + GET 请求提交的数据最多只有 1024 字节，而 POST 方式没有限制
            + ```URL = htψs://www. baidu.corn/s?wd=....```此处？后面的都是参数，键值对的形式存在此处wd表示要搜索关键字
            + POST一般是提交表单或上传文件，比如需要登陆，使用POST，也可以使用GET，但是用户名和密码直接暴露出来了，所以一般用POST
        + 其他请求方法：
            + HEAD：获取报头、
            + PUT：从客户端向服务器传送的数据取代指定文梢中的内容、
            + DELETE：请求服务器删除指定的页面、
            + CONNECT：把服务器当作跳板，让服务器代替客户端防问其他网页、
            + TRACE：囚显服务器收到的请求，主要用于测试或诊断
    + 2.请求的网址
        + 请求的网址，即统 资惊定位符 URL ，它可以唯一确定我们想请求的资源
    + 3.请求头
        + 请求头，用来说明服务器要使用的附加信息，比较重要的信息有 Cookie Referer User-Agent等。
        ![3.png](https://wx2.sbimg.cn/2020/04/29/3.png)
        + Accept ：请求报头域，用于指定客户端可接受哪些类型的信息
        + Accept-Language ：指定客户端可接受的语言类型
        + Accept-Encoding ：指定客户端可接受的内容编码
        + Host：用于指定请求资源的主机 IP 和端口号，其内容为请求 URL 的原始服务器或网关的位置
        + Cookie（cookies） ：是网站为了辨别用户进行会话跟踪而存储在用户本地的数据。主要功能是维持当前访问会话。Cookies 里有信息标识了我们所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上 Cookies 并将其发送给服务器，服务器通过 Cookies 识别出是我们自己，并且查出当前状态是登录状态，所以返回结果就是登录之后才能看到的网页内容。
        + Referer ：此内容用来标识这个请求是从哪个页面发过来的，服务器可以拿到这 信息并做相应的处理，如做来源统计、防盗链处理等
        + User-Agent ：简称 UA ，它是一个特殊的字符串头，可以使服务器识别客户使用的操作系统及版本 浏览器及版本等信息 在做爬虫时加上此信息，可以伪装为浏览器；如果不加，很可能会被识别为爬虫。
        + Content-Type ：也叫互联网媒体类型（ Internet Media Type ）或者 MIME 类型，在 HTTP协议消息头中，它用来表示具体请求中的媒体类型信息。例如， text/html 代表 HTML 格式，image/gif 代表 GIF 图片， app lication/json代表JSON 类型等。
    + 4.请求体
        + 请求体 般承载的内容是 POST 请求中的表单数据，而对于 GET 请求，请求体则为空
        ![42e63eb504b604f57.png](https://wx2.sbimg.cn/2020/04/29/42e63eb504b604f57.png)
        + 注意：Request Headers 指定 Content-Type application, x-www-form-urlencoded 只有设置Content-Type application/x-www-form-urlencoded ，才会以表单数据的形式提交
        + 另外，我们也可以Content-Type 设置为 pplication/ison 来提交 JSON 数据，或者设置为 multi part/form-data上传文件
+ ##### 1.6 响应
    + 响应，由服务端返回给客户端，可以分为：响应状态码（ Response Status Code ）、响应头
( Response Headers ）和响应体（ Response Body ）
    + 1.响应状态码：响应状态码表示服务器的响应状态 200表示正常响应
    + 2.响应头包含了服务器对请求的应答信息
    [![5.png](https://wx1.sbimg.cn/2020/04/29/5.png)](https://sbimg.cn/image/XOExD)
        + Date：标识响应产生的时间
        + Last-Modified：指定资源的最后修改时间
        + Content-Encoding：指定响应内容的编码
        + Server 包含务器的信息，比如名称、版本号等
        + Content-Type：文档类型 ，指定返回的数据类型是什么，如 text/ html代表返回 HTML 文档，application/x-javascript代表返回 JavaScript文件， image/jpeg 代表返回图片
        + Set Cookie：设置 Cookie响应头中的 Set Cookie告诉浏览器需要将此内容放在 Cookies中，下次请求携带Cookies请求
    + 3.响应体
    ![6.png](https://wx2.sbimg.cn/2020/04/29/6.png) （图片有误，非响应体内容）
        + 响应的正文数据都在应体中，比如请求网页时，它的响应体就HTML；请求一张图片时，响应体就是图片的二进 制数据，爬虫请求网页后，要解析的内容就是响应体
        + 点击response，就可以看到网页源代码也就是响应体的内容，它是解的目标

#### 2.网页的基础知识
+ ##### 2.1 网页的组成
    + 网页可分为3大部分一一－HTML、CSS、JavaScript（HTML相当于骨架， JavaScript相当于肌肉、css相当当于皮肤，三者结合才能形成完善的网页）
    + 1.HTML（Hype Text Markup Language）:超文本标记语言。网页包括文字、按钮、图片 视频等各种复杂元素，其基础构架就是HTML。
    + 2.CSS（Cascading Style Sheets）：层叠样式表。让页面变得美观。
    + 3.JavaScript（JS）：一种脚本语言。动态的交互信息，例如：下载进度条、提示框 轮播图等。
+ ##### 2.2 网页的结构
    + 有待完善
#### 3.爬虫的基本原理
+ ##### 3.1 爬虫概述  
    + 1.获取网页
        + 获取网页的源代码，源代码里包含了网页的部分有用信息 ，所以只要把源代码获取下来，就可以从中提取想要的信息了
        + Python中借助的库：urllib、requests
    + 2.提取信息
        + 利用正则表达式、XPath从抓取的源代码提取所需数据
    + 3.保存数据
        + 文件、数据库保存
    + 4.自动化程序
        + 让程序自动抓取数据
+ ##### 3.2 抓取数据
    + 无论是HTML、JSON还是二进制数据，都可以爬取
#### 4.Cookies基本原理
+ Cookies 指某些网站为了辨别用户身份 进行会话跟踪而存储在用户本地终端上的数据
+ 1.会话维持
    + 成功登录某个网站时，服务器会告诉客户端设置哪些cookies 信息，在后续访问页面时客户端会把 Cookies 发送给服务器，服务器再找到对应的会话加以判断.如果会话中的某些设置登录状态的变量是有效的，那就证明用户处于登录状态，此时返回登录之后才可以查看的网页内容，浏览器再进行解析便可以看到了.
    + 如果传给服务器的 Cookies 是无效的，或者会话已经过期了，我们将不能继续访问页面，此时可能会收到错误的响应或者跳转到登录页面重新登录
    + Cookies 和会话需要配合，一个处于客户端，一个处于服务端，二者共同协作，就实现了登录会话控制
+ 2.属性结构
    ![7.png](https://wx2.sbimg.cn/2020/04/29/7.png)
    + Name：Cookie的名称。一旦创建，该名称便不可更改
    + Value Cookie 的值。如果值为 Unicode 字符，需要为字符编码 如果值为二进制数据，则需要使用 BASE64 编码
    + Domain ：可以访问改Cookie的域名
    + Max Age：Cookie失效的时间， 单位为秒，也常和 Expires 一起使用，通过它可以计算有效时间 Max Age 果为正数 ，则cookie Max Age 秒之后失效 如果为负数，则关闭浏览器时 Cookie 即失效，浏览器也不会以任何形式保存该 Cookie
    + Path:Cookie 的使用路径 如果设置为／path/ ，则只有路径为 /path/ 的页面可以访问该Cookie 如果设置为人，则本域名下的所有页面都可以访问该 Cookie
    + Size：cookie的字段大小
    + HTTP 字段： Cookie的httponly属性，若属性为true ，则只有在HTTP头中会带有此Cookie 的信息，而不能通过 document.cookie 来访问此 Cookie
    + Secure Cookie：是否仅被使用安全协议传输。安全协议有 HTTPS、SSL 等，在网络上传输数据之前先将数据加密。默认为 false
+ Max Age或Expires字段的设置，一些持久化登录的网站把 Cookie 的有效时间和会话有效期设置得比较长，下次再访问页面时，仍然携带之前的 Cookie ，就可以直接保持登录状态
+ 注意：服务器无法判读浏览器是否关闭，而是服务器设置了失效时间，根据用户是否超过了失效时间，若超过服务器会关闭会话（以节省储存空间）。
#### 5.代理
+ ##### 5.1 基本原理
    + 代理实际上指的就是代理服务器，英文叫作 proxy server。作用：是代理网络用户去取得网络信息。也就是相当于一个处在本机和服务器中的一个中介
+ ##### 5.2 代理的作用
    + 突破 门身 IP 访问限制，访问一些平时不能访问的站点
    + 访问一些单位或团体内部资源（局域网）
    + 提高访问速度
    + 隐藏丘实 IP，防止 向身的IP被封锁
+ ##### 5.3 爬虫代理
+ 原因：
    + 1.爬虫爬取速度过快，在爬取过程中可能遇到同一个IP访问过于频繁的问题，此时网站就会让我们输入验证码登录或者直接封锁IP
    + 2.使用代理隐藏真实的 IP ，让服务器误以为是代理服务器在请求自己。这样便能更好的获取数据
+ ##### 5.4 代理的分类
+ 1.协议划分：
    + 暂时不想写

+ 2.匿名程度划分：
    + 透明代理
        代理服务器将客户端的信息转发至目标访问对象，并没有完全隐藏客户端真实的身份。即服务器知道客户端使
        用了代理IP，并且知道客户端的真实IP地址。
    + 普通匿名代理
        代理服务器用自己的IP代替了客户端的真实IP，但是告诉了目标访问对象这是代理访问。
    + 高匿代理
        代理服务器良好地伪装了客户端，不但用一个随机的IP代替了客户端的IP，也隐藏了代理信息，服务器不会觉到客户端是通过代理实现访问的，即用户仿佛就是直接使用代理服务器作为自己的客户端。
